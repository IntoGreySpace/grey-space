+++
Categories = ["Physical Reality"]
bibfile = "ccnlab.json"
+++

**Emergence** is perhaps the single most important phenomenon for understanding thorny and longstanding philosophical puzzles, including [[consciousness]] and [[free will]]. It is _not_ magic, but it nevertheless _seems_ like it.

{id="figure_gears" style="height:20em"}
![The principle of _emergence_, simply illustrated.  The gears on the left do not interact, and nothing interesting happens.  However, on the right, the interaction between the gears produces interesting, useful phenomena that _cannot_ be reduced to the individual gears _separately_. For example, the little gear will spin faster, but the larger one will have higher torque at its axel: these properties would be entirely different if either gear interacted with a different sized gear. Furthermore, the material that the gear is made from really doesn't matter very much: the same basic behavior would be produced by plastic, metal, wood, etc. Thus, even in this simple case, there is something just slightly magical and irreducible going on --- when two gears get together, something emerges that is more than the sum of the parts, and exists in a way independent of the parts, even while being entirely dependent on actually _having_ those parts to make it happen.](media/fig-gears.png)

Emergence can be illustrated in a very simple physical system, two interacting gears, as shown in [[#figure_gears]]. It is not mysterious or magical. On the other hand, it really is. You can make the gears out of any kind of sufficiently hard material, and they will still work. There might be subtle factors like friction and durability that vary. But over a wide range, it doesn't matter what the gears are made from. Thus, there is a level of _transcendence_ that occurs with emergence, where the behavior of the more complex interacting system does not depend on many of the detailed properties of the lower level parts. In effect, the interaction itself is what matters, and the parts are mere place holders. Of course, they have to be there, and meet some basic criteria, but they are nevertheless replaceable.

The following properties are of greatest importance:

* For any _specific_ individual physical system, there is a direct _one-to-one mapping_ ([[supervenience]]) between the [[physical reality]] of the underlying substrate and all the emergent phenomena that arise from it. There is fundamentally nothing magic or non-physical about emergence, and this distinguishes the so-called "weak" form of emergence that we are talking about, from a truly magical "strong" form that would violate this property ([[@Bedau97]]).

* However, emergent phenomena have a _many-to-one mapping_ between the physical substrate and an emergent phenomenon, such that the same emergent phenomenon can be realized with _different_ physical substrates (e.g., the different materials that gears can be made from). We can call this **substrate invariance** (or _multiple realizability_ in the [[functionalism]] literature), and it provides a [formal definition](#formal definition) for emergence, that can carry a lot of weight in further reasoning about it, as we develop below.

* This many-to-one mapping or substrate invariance is a more precise way of saying that emergent phenomena cannot be directly reduced to the "sum" of their constituent parts or physical substrate: some kind of further special configuration of these parts is _necessary_, and also _sufficient_ in the sense that _any_ substrate that provides such a special configuration will do.

* Furthermore, this many-to-one mapping holds _within the same physical system_ over time: one could progressively swap out all of the physical components of the system over time, and if rebuilt to support the same higher-level interactions upon which the emergent phenomena depend, these emergent level phenomena would persist. This is the famous [[Ship of Theseus]] thought experiment, and it is much more of a reality than you might otherwise appreciate. All of the cellular components in your own body are constantly being rebuilt on the time scale of days ([[@RolfsFreyShiEtAl21]]).

* Therefore, the continued stable existence of _you_, including your the ability to access remote memories and everything you've learned over your lifetime, depends on this many-to-one mapping of emergent phenomenon, because your physical substrate is in constant flux. To be perfectly clear, you _are_ an emergent phenomenon.

* More generally, the converse implication of substrate invariance also holds: any phenomenon that we deem to persist or hold across instances (i.e., across multiple different physical substrates) is therefore an emergent phenomenon. Thus, essentially all of the referents of our verbal discourse are emergent phenomena.

One critical consequence of this invariant, many-to-one nature of emergent properties is that it enables one to instantiate emergent phenomena _virtually_ inside a digital computer, by running simulations with equations that capture the essential interactions necessary to support the phenomenon in question. Uncontroverisally, such simulations are used to simulate emergent phenomena in atmospheric weather dynamics, to generate increasingly accurate weather predictions. Likewise, emergent dynamics in physical systems including waves, spin glasses, fluid and gas dynamics, and all manner of real-world engineering problems are routinely simulated on computers.

Of closest relevance to the focus of this overall discourse, computers can simulate the emergent phenomena of the brain, by capturing the essential interactions between neurons, and thereby help us understand all of the relevant phenomena of the mind, including [[consciousness]]. Thus, by the very definition of emergence, it should in principle be possible to capture all of the essential properties of the human mind in a computer simulation.

## Formal definition

[[@^Bedau97]] postulates that emergent phenomena can be formally defined by virtue of only being derivable from the underlying substrate through a process of simulation.

This is too weak and indirect of a definition in my opinion. A much simpler and stronger definition, given above, is that there is a **many-to-one mapping** between physical substrate and emergent phenomena, such that _some significant class_ of specific details about the nature of the substrate are _irrelevant_ for the emergent phenomenon: i.e., it is _invariant_ over that set of details. This gives rise to the **substrate invariance** definition of emergent phenomena.

In the gears example, all that matters is that the physical substrate exhibit a sufficient degree of physical rigidity, such that forces acting on the teeth are properly transmitted to the axle, and the gear retains its overall shape.

Furthermore, we can provide a positive definition of the properties that _are_ critical for the function of the gears as an emergent phenomenon, at a level that is independent of a specific physical substrate. Namely, it is the _shape_ of the gears that matters, specifically with respect to the ability of the teeth to properly enmesh with each other, the circular overall shape of the gear, the relative sizes of the two gears, and the specific positioning of the two gears such that the teeth properly engage, etc. Emergent properties tend to involve relationships and configurations of elements within a physical system, as in this example.

In simple such systems with well-defined properties, it is clear that we can define a strong _equivalence class_ of a two-gear system, such that any realization of such a system that has specific values of these properties should behave in the same manner.

One might argue that there are still residual low-level details about the behavior of the system that will depend on the underlying physical substrate, e.g., the rate of wear, degree of friction, or effects of thermal expansion (all of which may be important for real-world applications, especially for example in accurate gear-based clocks). Nevertheless, one can still reasonably define equivalence classes for such properties (and increase the realism of a digital simulation to include them), so the principle of substrate invariance remains intact, as long as the phenomenon in question doesn't become identically synonymous with one specific clump of matter.

## Do emergent phenomena "really exist"?

One concern about emergent phenomena is that they are fundamentally [[subjective]] in nature, dependent on the conceptual space of a cognitive observer, rather than objectively real properties of a physical system.

This view can be justified by the [[supervenience]] perspective with respect to _a single instantiation_ of a physical system: such a system could plausibly be described at the lowest possible level of [[physical reality]], and the strong one-to-one mapping across all levels for a single such system admits to no "metaphysical gaps": it is all just physics in the end.

However, once you consider _multiple_ physical systems, or the stable behavior of a given physical system over time despite significant changes in its underlying substrate, the substrate invariance property becomes manifest, and it arguably provides a much more generative and succinct explanation for why these systems behave as they do.

Nevertheless, the very ability to compare across two physical systems, or across one system at different points in time, is only available to cognitive observers, as we discuss in the page on [[physical reality]]. In the "bare reality" of the physical systems themselves, there is no emergence, no comparisons, only physics.

Thus, it seems difficult to escape the conclusion that emergence is in fact a cognitive construct that we use to provide a simpler, more compact explanation of a _class_ of physical systems, according to these substrate invariances.

Despite this conclusion, it is also the case that such substrate invariances are not _arbitrary_ constructions of our minds: we cannot just randomly invent emergent phenomena willy-nilly.

Thus, we can further conclude that emergent phenomena are [[objective]] in the sense that multiple different cognitive observers who have established a reliable means of communication, and who engage in the basic rules of the [[scientific method]], can come to a stable, reliable mutual agreement about the nature of such phenomena. In other words, we can agree on the predictions of the outcomes of experiments performed on such physical systems, based on the emergent-level descriptions of such systems _only_. Thus, the emergent level description provides predictive validity as a theory of overall system function.

In summary, from one perspective emergent phenomena are not "real" in the sense of something that is somehow part of the base-level physical laws of the universe. But very few things admit to this level of reality, so it is perhaps not that useful of a criterion. On the other hand, they are just as real as any other construct in our objective scientific language, from cells to waves to birds to the brain. Indeed all of these things could be described as emergent phenomena, and it is hard to imagine how we could ever develop a systematic understanding of the world without these kinds of more abstract emergent concepts.

## Functionalism

Emergence is closely related to [[functionalism]], which seeks to describe mental processes at a more abstract level in terms of systematic functional _relationships_, as contrasted with more basic physical substrates. A core property of functionalism is _multiple realizability_: the idea that a given mental state can be realized by different underlying physical substrates ([[@Putnam67]]). This is identical to the principle of substrate invariance and overall it is unclear if there are any substantive differences between functionalism and emergence. Nevertheless, it is interesting that the wikipedia article on [functionalism](https://en.wikipedia.org/wiki/Functionalism_(philosophy_of_mind)) does not mention [emergence](https://en.wikipedia.org/wiki/Emergence) and vice-versa. The extensive discussion in [[@^Fodor81]] about functionalism develops many of the same points as stated above about simulation of emergent phenomena.

## Digital computers

Digital computers have multiple important properties in relation to emergence. First, as emphasized by [[@^Fodor81]], a computer exhibits a clear form of separation between the underlying hardware and the software that runs on top of it: the same software program can run on many different types of hardware, including different physical instances of the same computer type, and there are computers with wildly different underlying hardware implementations at all levels. The three different levels of description proposed by [[@^Marr81]], _computational_, _algorithmic_, and _implementational_, were similarly derived from consideration of digital computers, and entail three different levels of emergent phenomena.

Despite the clarity of the separation between software and hardware in a computer, it remains the case that any actual individual instance of a computer running a given software program can be described entirely at the physical level, in terms of the flow of electrons and the states of the various logic gates involved. It is only once we consider the multiple realizability of the same software program across different hardware that the distinctions become apparent.

A computer is also special because its very design maximizes the substrate invariance property underlying emergent phenomena. Specifically, computer hardware has specific mechanisms that allow electrical states stored in arbitrary locations in a uniform block of memory to control the subsequent flow of these same electrical states over time through the system. Central to this ability is the basic [[logic gate]], where a control voltage signal determines what happens along a separate electrical pathway. The cumulative effect is to create a highly flexible electrical system that can route electrical signals conditioned on the states of other electrical signals, organized fundamentally according to the computationally universal [[Turing machine]] (actually a [[von Neumann architecture]]), so that it can support any kind of computation.

The ability of a digital computer to simulate any kind of other physical system, and thereby realize the substrate invariance property, depends on this computational universality. As noted above, any individual actual computer running a specific software program could in principle be completely described according to the basic physics of all of its myriad components. Therefore, it is does not have any extra-physical "magic": all of the magic comes from the universal flexibility of its design, and the level separation is only evident when comparing across machines and across time within a given machine.

## Causality across levels

A key question about emergence, particularly for the issue of [[free will]], is the nature of causal determinism in the behavior of an emergent system. The notion of _substrate invariance_ seems to suggest that the behavior of an emergent system is independent of the lower level substrate, but how well does this actually hold up?

At one level, to reiterate again, it is theoretically possible to describe the behavior of any individual physical system using the basic laws of physics at the atomic scale. Nevertheless, leveraging the example of the digital computer, it is much more efficient to describe the behavior of a computer at the level of the software program that it is running. Furthermore, when we run that same program across multiple different computers, or across time on the same computer, it becomes clear that the "true" causal factor driving the behavior of the system is in fact the software. But again, this level of understanding is only available to the cognitive observer with a sufficiently deep understanding of the nature of the system.

Critically, digital computers are specifically designed so as to _insulate_ the overall behavior of the system from the random details of underlying electrical signals on which they are built. Logic gates specifically impose a strong, high threshold between the on and off binary states, which significantly reduces the impact of random thermal noise. Error correcting components further reduce the impacts of noise, resulting in highly reliable overall systems with very low error rates. In effect, this means that the physics at the lower level is all but irrelevant for the higher-level behavior of the system.

This is not a _necessary_ property of any given physical system. Indeed, there have been attempts to create computers based on _analog_ circuitry, without digital thresholding. These computers have largely failed, due to the exponential accumulation of thermal noise. In this case, the constantly changing physical substrate is directly propagated "upwards" in the larger-scale behavior of the system, and this prevents the system from exhibiting substrate invariance.

Therefore, the strong thresholding property of a digital computer can be seen as an _essential_ property for it to exhibit such a powerful form of emergent behavior. Interestingly, neurons in the brain also have a strong thresholding property, via their "spiking" behavior, and there is every reason to believe that this property is essential for preventing the same kind of runaway noise propagation behavior as is present in purely analog circuits.

Thus, perhaps the ability of the brain to also exhibit a strong level of substrate invariance is also directly related to this threshold spiking behavior of neurons.

Interestingly, there is considerable hype surrounding quantum computing devices. However, many such devices are essentially analog computers, and they suffer from runaway thermal noise problems. 

Another way in which a system can achieve substrate invariance is through the _law of large numbers_: if the higher-level phenomenon depends on a statistical "average" across many noisy lower-level states, then the impact of such noise decreases rapidly as the number of random elements increases. The paradigmatic example of this form of emergent phenomenon is _temperature_ as an emergent macroscopic property based on the averaged brownian random trajectories of the atomic substrate.

Biological systems at the cellular level also have specific mechanisms that result in strong decoupling from the lower-level physical substrate. Specifically cells are constantly regenerating their molecular constituents because these constituents inevitably become deformed over time (wear and tear), and the mechanisms of this molecular regeneration are based on stored "programs" in a very stable molecular structure: DNA. Thus, cells are constantly regenerating _the same_ physical structures over and over, according to a stored software program, effectively insulating themselves from all the lower-level physical noise and destruction.

In summary, we can conclude that it is _possible_, but not _necessary_ for a physical system to become effectively decoupled from its underlying physical substrate in terms of the causal mechanisms that drive its behavior, for example via a strong thresholding mechanism. In such a case, we can [[objectively]] state with confidence that the microscopic behavior of the physical substrate is essentially irrelevant for the macroscopic, emergent behavior of the overall system. Instead, the behavior of such a system is determined by the _software_ that is driving it: i.e., the specific higher-level configuration of the properties that actually do govern its emergent behavior.

In the case of the human brain and [[free will]], it is therefore objectively reasonable to conclude that we can engage in a deliberative thought process that is governed by the "values" and "morals" that we have learned over a lifetime of experience, rather than by the random thermal noise of the atoms in our brains. In this way, we can achieve the emergent phenomenon of free will.



